---
title: "![](DEEP_Header.png){out.width=1407px}"
date:  " <i> Report Created: `r format(Sys.Date(), '%B %Y')`</i>"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    toccolor: 'black'
    theme: lumen
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(
  comment = '', fig.width = 12, fig.height = 7, warning= FALSE, message = FALSE, fig.align ="left")
```

```{r LIBRARY,include=FALSE}
#Install packages if not done already 
#install.packages("dplyr")
#install.packages("lubridate")
#install.packages("plotly")
#install.packages("tidyverse")
#install.packages("htmlwidgets")
#install.packages("htmltools")
#install.packages("gt")
#install.packages("padr")
#install.packages("zoo")
#install.packages("magrittr")
library(dplyr)
library(lubridate)
library(plotly)
library(tidyverse)
library(htmlwidgets)
library(htmltools)
library(gt)
library(padr)
library(zoo)
library(magrittr)
```

```{r format, echo=FALSE}
setwd("P:/Community Monitoring/Working/AQMesh/Data_Files")

#listing all files
all_files <- list.dirs(path = "P:/Community Monitoring/Working/AQMesh/Data_Files")

#reformatting the AQMesh gas files, this will make a list of files that contain that file pattern (so make sure its that file pattern!)
gas_files <- list.files(path = all_files, pattern = "aqmeshgasdata")
AQ_gaslist <- lapply(gas_files, read.csv)

for (i in 1:length(AQ_gaslist)){
  #Subsetting based on the needed columns
  AQ_gaslist[[i]] <- AQ_gaslist[[i]][c("reading_datestamp", "co_prescaled", "no_prescaled", "no2_prescaled", "o3_prescaled", "eo_prescaled", "aux1_prescaled", "aux2_prescaled", "humidity")] 
}

#binding the rows!
AQ_gas <- bind_rows(AQ_gaslist)

#timestamp
AQ_gas$timestamp <- as.POSIXct(AQ_gas$reading_datestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC")
AQ_gas$timestamp <- with_tz(AQ_gas$timestamp, "EST")

#I'm stealing your script for this section for now. 
#summarizing by hour
completeness_threshold <- 0.75 #for comparison to regulatory data
AQ_gas_avg <- AQ_gas %>%
  mutate(hour = format(timestamp, "%Y-%m-%d %H:00:00")) %>%
  group_by(hour) %>%
  summarize(AQ_co = if (sum(!is.na(co_prescaled))/4 >= 
                         completeness_threshold) mean(co_prescaled, na.rm = TRUE) else NA_real_,
            AQ_no = if (sum(!is.na(no_prescaled))/4 >= 
                         completeness_threshold) mean(no_prescaled, na.rm = TRUE) else NA_real_,
            AQ_no2 = if (sum(!is.na(no2_prescaled))/4 >= 
                          completeness_threshold) mean(no2_prescaled, na.rm = TRUE) else NA_real_,
            AQ_o3 = if (sum(!is.na(o3_prescaled))/4 >= 
                         completeness_threshold) mean(o3_prescaled, na.rm = TRUE) else NA_real_,
            AQ_eo = if (sum(!is.na(eo_prescaled))/4 >= 
                         completeness_threshold) mean(eo_prescaled, na.rm = TRUE) else NA_real_,
            AQ_ws = if (sum(!is.na(aux1_prescaled))/4 >= 
                         completeness_threshold) mean(aux1_prescaled, na.rm = TRUE) else NA_real_,
            AQ_wd = if (sum(!is.na(aux2_prescaled))/4 >= 
                         completeness_threshold) mean(aux2_prescaled, na.rm = TRUE) else NA_real_)
AQ_gas_avg$hour <- as.character(format(AQ_gas_avg$hour))
names(AQ_gas_avg)[1] <- "Date_Time"

#reformatting the AQMesh pm files, same as gas just pm 
pm_files <- list.files(path = all_files, pattern = "aqmeshpmdata")
AQ_pmlist <- lapply(pm_files, read.csv)

for (i in 1:length(AQ_pmlist)){
  #Subsetting based on the needed columns
  AQ_pmlist[[i]] <- AQ_pmlist[[i]][c("reading_datestamp", "pm10_prescale", "pm2_5_prescale", "pm1_prescale", "temperature_f", "humidity")] 
}

#binding the rows!
AQ_pm <- bind_rows(AQ_pmlist)

#timestamp!
AQ_pm$timestamp <- as.POSIXct(AQ_pm$reading_datestamp, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC")
AQ_pm$timestamp <- with_tz(AQ_pm$timestamp, "EST")

#summarizing by hour
completeness_threshold <- 0.75 #for comparison to regulatory data

AQ_pm_avg <- AQ_pm %>%
  mutate(hour = format(timestamp, "%Y-%m-%d %H:00:00")) %>%
  group_by(hour) %>%
  summarize(AQ_pm10 = if (sum(!is.na(pm10_prescale))/4 >= 
                           completeness_threshold) mean(pm10_prescale, na.rm = TRUE) else NA_real_,
            AQ_pm2.5 = if (sum(!is.na(pm2_5_prescale))/4 >= 
                            completeness_threshold) mean(pm2_5_prescale, na.rm = TRUE) else NA_real_,
            AQ_pm1 = if (sum(!is.na(pm1_prescale))/4 >= 
                          completeness_threshold) mean(pm1_prescale, na.rm = TRUE) else NA_real_,
            AQ_tempF = if (sum(!is.na(temperature_f))/4 >= 
                            completeness_threshold) mean(temperature_f, na.rm = TRUE) else NA_real_,
            AQ_RH = if (sum(!is.na(humidity))/4 >= 
                         completeness_threshold) mean(humidity, na.rm = TRUE) else NA_real_)
AQ_pm_avg$hour <- as.character(format(AQ_pm_avg$hour))
names(AQ_pm_avg)[1] <- "Date_Time"

#Pulling in East Hartford reference files, even though its one file I'm still doing list, just so you have the option to just pull new files
#save files from Envista as csv, just makes it a tad easier in R
#Also Envista is very weird, you have to open this file and remove the bottom summary BECAUSE this also changes the time format!
EH_files <- list.files(path = all_files, pattern = "East_Hartford")
EH_list <- lapply(EH_files, read.csv, skip = 2)

for (i in 1:length(EH_list )){
  #removing that random row that isnt needed
  EH_list[[i]] <- EH_list[[i]][-c(1),]
}
EH <- bind_rows(EH_list)

#Timestamp
EH$Date_Time  <- as.POSIXct(EH$Date...Time, format = "%m/%d/%Y %H:%M", TZ= "UTC")
EH <- pad(EH)
EH$Date_Time <- as.character(format(EH$Date_Time))
EH <- EH[,-1]

#Making one data frame with the data merged by hour 
aq <- merge(AQ_gas_avg, AQ_pm_avg, by="Date_Time")
all <- merge(EH, aq, by="Date_Time", all.x = TRUE)

#Writing a csv for all data
write.csv(all, "P:/Community Monitoring/Working/AQMesh/CT_AQMeshData_2023-2024.csv", row.names=FALSE)

#Making individual dataframes to compare each pollutant
O3 <- all[, c("Date_Time", "AQ_o3", "O3")]
names(O3) <- c("Date_Time", "AQ", "EH")
NO2 <- all[,c("Date_Time", "AQ_no2", "NO2")]
names(NO2) <- c("Date_Time", "AQ", "EH")
PM25 <- all[,c("Date_Time", "AQ_pm2.5", "T640_PM25")]
names(PM25) <- c("Date_Time", "AQ", "EH")
PM10 <- all[,c("Date_Time", "AQ_pm10", "T640_PM10")]
names(PM10) <- c("Date_Time", "AQ", "EH")
WS <- all[,c("Date_Time", "AQ_ws", "WSsonic")]
names(WS) <- c("Date_Time", "AQ", "EH")
WD <- all[,c("Date_Time", "AQ_wd", "WDsonic")]
names(WD) <- c("Date_Time", "AQ", "EH")
Temp <- all[,c("Date_Time", "AQ_tempF", "TMPOS")] 
names(Temp) <- c("Date_Time", "AQ", "EH")
RH <- all[,c("Date_Time", "AQ_RH", "RH")] 
names(RH) <- c("Date_Time", "AQ", "EH")

#Quickly changing AQ Temp to Celsius
Temp$AQ <- as.numeric(Temp$AQ)
Temp$AQ <- ((Temp$AQ - 32) * 5/9)

#Adding a column with the data type, sets up for the loops
O3$Data_Type <- "O3"
NO2$Data_Type <- "NO2"
PM25$Data_Type <- "PM 2.5"
PM10$Data_Type <- "PM 10"
WS$Data_Type <- "Wind Speed"
WD$Data_Type <- "Wind Direction"
Temp$Data_Type <- "Temperature"
RH$Data_Type <- "Relative Humidity"

#Binding gases then pm into a dataframe
gases <- rbind(O3,NO2)
pm <- rbind(PM25,PM10)
met <- rbind(WS,WD,Temp,RH)

#Adding a units column 
gases$units <- "(ppb)"
pm$units <- "(µg/m³)"
met$units <- " "

#Combinded dataframe for graphing!
comb_full <- rbind(gases, pm, met)

#First pulling/renaming the values that are < -100 since these are not tracking data! 
#mostly just so these dont get counted as outliers 
comb_full$AQ <-replace(comb_full$AQ, comb_full$AQ < -100, NA)

#This is detecting outliers based on the IQR Method
#It basically will find values in Q1 and Q3 multiple by 1.5 and fence off those values, BUT it will rename the outlier "Outlier"
#This could be another good characteristic to judge (percentage of outliers in the dataset)
detect_outlier <- function(x,iqtimes=1.5) {
  # calculate first quantile
  Quantile1 <- quantile(x, probs=.25, na.rm = T)
  # calculate third quantile
  Quantile3 <- quantile(x, probs=.75, na.rm = T)
  # calculate inter quartile range
  IQR = Quantile3-Quantile1
  # return true or false
  outiers <- x > Quantile3 + (IQR*iqtimes) | x < Quantile1 - (IQR*iqtimes)
  x[which(outiers)] <- "outlier"
  return(x)
}

#designating what columns to clean!
cols_to_clean <- names(comb_full)[sapply(comb_full, is.numeric)]

#Running the function
comb_out <- comb_full %>% group_by(Data_Type) %>%
  mutate(across(cols_to_clean , ~detect_outlier(.,iqtimes=1.5)))

#Only keeping numeric data, basically this changes outlier/no data to "NA" for this specific dataframe, so it can be graphed
#graphs get very mad about non-numeric data
comb <- comb_out
comb$AQ <- as.numeric(comb$AQ)
comb$EH <- as.numeric(comb$EH)

#dropping NAs from the date column
comb_out <- comb_out %>% drop_na(Date_Time)

#changing na to "no_data" so this can be used to calc on table
comb_out$AQ[is.na(comb_out$AQ)] <- "no_data"
comb_out$EH[is.na(comb_out$EH)] <- "no_data"

#This adds the quarter an year, but I dont like the format so also changing that
comb$Quarter <- as.yearqtr(comb$Date_Time, format = "%Y-%m-%d")
comb$Quarter <- format(comb$Quarter, format = "%q (%Y)")

```

```{r csv link, echo =FALSE}
#This is how the csv is inserted as a link, then is added to the text below
readBin("CT_AQMeshData_2023-2024.csv", "raw", file.info("CT_AQMeshData_2023-2024.csv")$size) %>% 
  openssl::base64_encode() -> encoded
```

An AQMesh air quality monitoring sensor was installed at a monitoring site in East Hartford, Connecticut to evaluate its performance tracking gas, particulate and meteorology data over a year long time frame. Hourly data for O3, NO2, PM2.5, PM10, temperature and relative humidity were compared to reference monitors located at the same site. The full downloadable dataset used is located here <a download="CT_AQMeshData_2023-2024.csv" href="`r sprintf('data:text/csv;base64,%s', encoded)`">Download CSV</a>. 

# Sensor Details 
## AQMesh Specifications
<table border="2" style="border-collapse: collapse; border-color: black;">
<tr style="background-color: #0D2C6C; color: white; text-align: left;">
<td style="font-size: 16px; padding: 8px; border: 1px solid black;"><b>Possible Configuration</td>
<td style="font-size: 16px; padding: 8px; border: 1px solid black;"><b>Evaluated Configuration</td>
<td style="font-size: 16px; padding: 8px; border: 1px solid black;"><b>Cost</td>
<td style="font-size: 16px; padding: 8px; border: 1px solid black;"><b>Data Access</td>
<td style="font-size: 16px; padding: 8px; border: 1px solid black;"><b>Power Supply</td>
<td style="font-size: 16px; padding: 8px; border: 1px solid black;"><b>Considerations</td>
<td style="font-size: 16px; padding: 8px; border: 1px solid black;"><b>Reference Monitors Compared</b></td>
</tr>
</tr>
<tr style="background-color: #white; color: black;">
<td style=" text-align: left; vertical-align:top; padding: 8px; border: 1px solid black;"> <b> Particulates: </b> PM1, PM2.5, PM10 <br> <b> Gases: </b> NO, NO2, O3, CO, CO2, TVOC, SO2, EtO <br> <b> Meteorology: </b> WS/WD, Baro Pressure, Temp, RH </td>
<td style ="vertical-align:top; padding: 8px; border: 1px solid black;"><b> Particulates: </b> PM2.5, PM10 <br> <b> Gases: </b>  NO2, O3 <br> <b> Meteorology: </b> Temp, RH
</td>
<td style ="vertical-align:top; padding: 8px; border: 1px solid black;"> <b> Sensor: </b> $6,663.00 <br> <b> Sonic Anemometer: </b> $4,998.00 <br> <b> Solar Configuration: </b> $1,967.00 <br> <b> Cellular Communications (Annual): </b> $420.00 <br> <b> API or Dashboard: </b> $1,260.00
</td>
<td style ="vertical-align:top; padding: 8px; border: 1px solid black;"> Basic Download (CSV), API, Web Application <br> (Data stored locally on SD card)
</td>
<td style ="vertical-align:top; padding: 8px; border: 1px solid black;"> Smart Solar Pack, Rechargeable NiMH battery, Mains DC Power
</td>
<td style ="vertical-align:top; padding: 8px; border: 1px solid black;"> <b> Time Resolution: </b> 1 minute to 1 hour intervals <br> <b> Dimensions: </b> 430 (H) x 220 (W) x 170 (L) mm (including antenna) <br> <b> Weight: </b> 2-2.7 kg
</td>
<td style ="vertical-align:top; padding: 8px; border: 1px solid black;"> <b> O3: </b> Teledyne N400 
<br>
<b> NO2: </b> Teledyne T500U
<br>
<b> PM2.5 & PM10: </b> Teledyne API T640X
<br>
<b> Temp & RH: </b> AutoMet 580
</td>
</tr>
</table>

## Setup
```{r, echo = FALSE, out.width = '49%', out.height= '49%', fig.show = 'hold', fig.align = 'center', fig.cap=' '}
knitr::include_graphics(c("AQMesh1.png", "AQMesh2.png"))
```

<br>

```{r timeseries, results = 'asis', echo = FALSE}
#This makes a list of timeseries plots with two loops, first through the quarter/year then through datatype
#Output is a timeseries graph for each quarter/year for each measurement 
timeseries = list()

idx <- 1
for (i in unique(comb$Quarter)){
  
  i_comb <- subset(comb, comb$Quarter==i)
  
for (j in unique(i_comb$Data_Type)){
  
  j_comb <- subset(i_comb, i_comb$Data_Type==j)
  
   plot_name <- paste0("Q_", i, "_", j)

  timeseries[[plot_name]] <- plot_ly(data= j_comb, x = ~Date_Time) %>%
    add_lines(y = ~EH, name = "Reference", line = list(color = "black"), opacity = 0.9) %>%
    add_lines(y = ~AQ, name = "AQMesh ", line = list(color = "blue"), opacity = 0.6) %>%
    layout(title = list(text = paste0("AQMesh Sensor: ", unique(j_comb$Data_Type)," Comparision",
                                      "<br>",
                                      "<sup>", 
                                       "Quarter ", unique(i_comb$Quarter),  "<sup>")),
           legend = list(orientation = 'h', title=list(text="Monitor Type:")), 
           xaxis = list(title = " ",
                        type = 'date',
                        tickformat = "%B %d <br>%Y"),
           annotations = list(x = 0.60, y = -0.17, text = paste0("<i> 
                                                             *Outliers removed from AQMesh dataset using IQR Method.                                                                  </i>"), 
      showarrow = F, xref='paper', yref='paper', 
      xanchor='right', yanchor='auto', xshift=0, yshift=0,
      font=list(size=12, color="grey")),
           yaxis = list(title = paste0(unique(j_comb$Data_Type), " ", unique(j_comb$units)), rangemode = 'tozero'))
  idx <- idx + 1

}}

```

# Timeseries Comparison

AQMesh hourly data for O3, NO2, PM2.5, PM10, temperature and relative humidity were compared by quarter to reference values (Q1: January-March, Q2: April-June, Q3: July-September, Q4: October-December).

## O3 {.tabset .tabset-fade .tabset-pills}
```{=html}
<style>
.list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus{
     background-color:   #0D2C6C;
}
     body {
     color: black;
}
 .nav-pills>li>a {
     color: black;
     }
  .nav-pills>li>a:hover, .nav-pills>li>a:focus, .nav-pills>li.active>a,     .nav-pills>li.active>a:hover, .nav-pills>li.active>a:focus{
     background-color:   #0D2C6C;
      }
h1, .h1 {
    font-size: 36px;
    color: #0D2C6C;
    font-weight: bold;
}
.main-container {
  max-width: 1400px !important;
  margin: auto;
}


</style>
```
### Quarter 3 (2023)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_3 (2023)_O3']]
```

### Quarter 4 (2023)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_4 (2023)_O3']]
```
### Quarter 1 (2024)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_1 (2024)_O3']]
```
### Quarter 2 (2024)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_2 (2024)_O3']]
```

## NO2 {.tabset .tabset-fade .tabset-pills}
### Quarter 3 (2023)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_3 (2023)_NO2']]
```

### Quarter 4 (2023)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_4 (2023)_NO2']]
```

### Quarter 1 (2024)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_1 (2024)_NO2']]
```

### Quarter 2 (2024)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_2 (2024)_NO2']]
```
## PM 2.5 {.tabset .tabset-fade .tabset-pills}
### Quarter 3 (2023)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_3 (2023)_PM 2.5']]
```
### Quarter 4 (2023)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_4 (2023)_PM 2.5']]
```
### Quarter 1 (2024)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_1 (2024)_PM 2.5']]
```
### Quarter 2 (2024)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_2 (2024)_PM 2.5']]
```

## PM 10 {.tabset .tabset-fade .tabset-pills}
### Quarter 3 (2023)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_3 (2023)_PM 10']]
```

### Quarter 4 (2023)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_4 (2023)_PM 10']]
```

### Quarter 1 (2024)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_1 (2024)_PM 10']]
```

### Quarter 2 (2024)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_2 (2024)_PM 10']]
```

## Temperature {.tabset .tabset-fade .tabset-pills}
### Quarter 3 (2023)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_3 (2023)_Temperature']]
```
### Quarter 4 (2023)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_4 (2023)_Temperature']]
```
### Quarter 1 (2024)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_1 (2024)_Temperature']]
```
### Quarter 2 (2024)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_2 (2024)_Temperature']]
```

## Relative Humidity {.tabset .tabset-fade .tabset-pills}
### Quarter 3 (2023)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_3 (2023)_Relative Humidity']]
```
### Quarter 4 (2023)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_4 (2023)_Relative Humidity']]
```
### Quarter 1 (2024)
```{r, results = 'asis', echo = FALSE}
timeseries[['Q_1 (2024)_Relative Humidity']]
```
### Quarter 2 (2024)
```{r results = 'asis', echo = FALSE}
timeseries[['Q_2 (2024)_Relative Humidity']]
```
<br/>

```{r, results = 'asis', echo = FALSE}
#correlation plot
#Removing nas for this one because correlation plots wont just ignore them
comb <- na.omit(comb)

correlation <- tagList()
idx <- 1
for (i in unique(comb$Data_Type)){
  
  i_comb <- subset(comb, comb$Data_Type==i)

  lm_calc <- lm(i_comb$AQ ~ i_comb$EH)
  slope <- coef(lm_calc)[2]
  y <- coef(lm_calc)[1]
  r <- summary(lm_calc)$r.squared
  
corrplot_name <- paste0(i)
  
correlation[[corrplot_name]] <-plot_ly(data = i_comb) %>% 
  add_markers(x = i_comb$EH, y = i_comb$AQ, name = " ", marker = list(color = "lightsteelblue",
                                                                            line = list(color = "#0D2C6C",width = 1.3))) %>%
  add_lines(x = i_comb$EH, y = fitted(lm(i_comb$AQ ~ i_comb$EH)),name = " ", line=list(color = "black", width= 1)) %>%
  layout(showlegend = F, 
         title = list(text = paste0("AQMesh Sensor: ", 
                                                   unique(i_comb$Data_Type)," Correlation ", unique(i_comb$units), "<br>",
                                                   "<sup>", "y=", round(slope, 3), "x + ", round(y,3), "  ", "R\u00b2", "=", round(r,3),"<sup>")),
         annotations = list(x = 0.60, y = -0.07, text = paste0("<i> 
                                                             *Outliers removed from AQMesh dataset using IQR Method.                                                                  </i>"), 
      showarrow = F, xref='paper', yref='paper', 
      xanchor='right', yanchor='auto', xshift=0, yshift=0,
      font=list(size=12, color="grey")),
         xaxis = list(title = "Reference", rangemode = 'tozero'), 
         yaxis = list(title = "AQMesh", rangemode = 'tozero'))
idx <- idx + 1

}

```

# Correlation Comparison
## AQMesh and Reference Correlation
### Gases {.tabset .tabset-fade .tabset-pills}
#### O3
```{r, results = 'asis', echo = FALSE}
correlation[['O3']]
```
#### NO2
```{r, results = 'asis', echo = FALSE}
correlation[['NO2']]
```

### Particulates {.tabset .tabset-fade .tabset-pills}
#### PM2.5
```{r, results = 'asis', echo = FALSE}
correlation[['PM 2.5']]
```
#### PM10
```{r, results = 'asis', echo = FALSE}
correlation[['PM 10']]
```

### Meteorology {.tabset .tabset-fade .tabset-pills}
#### Temperature
```{r, results = 'asis', echo = FALSE}
correlation[['Temperature']]
```
#### Relative Humidity
```{r, results = 'asis', echo = FALSE}
correlation[['Relative Humidity']]
```

```{r, echo=FALSE, results = 'asis'}

#finding outliers
o <- comb_out %>%
  group_by(Data_Type) %>%
  count(AQ) 

#This is just finding the outlier percentage
o <- o %>%
  group_by(Data_Type) %>%
  mutate(percent = n/nrow(o))
Outlier <- subset(o, AQ == "outlier")
Outlier$percent <- Outlier$percent *100

#This is just finding the no data percentage
n <- subset(o, AQ == "no_data")
names(n)[4] <- "cpercent"
n$cpercent <- n$cpercent * 100
n$complete <- 100 - n$cpercent

#Root mean square error
comb <- na.omit(comb)
rsme <- comb %>%
  group_by(Data_Type) %>%
 summarize(
    RMSE = sqrt(mean((EH - AQ)^2))
  )
  
Outlier <- merge(rsme, Outlier, by = "Data_Type", all.x = TRUE)
Outlier <- merge(Outlier, n, by = "Data_Type", all.x = TRUE)

#setting up data for a table
EH_AQ <- do.call(rbind, lapply(unique(comb$Data_Type), function(d) {
  EH_AQ_model <- lm(AQ ~ EH, data = comb[comb$Data_Type == d,])
  data.frame(Data_Type = d, Intercept = coef(EH_AQ_model)[1],
             Slope = coef(EH_AQ_model)[2], r_squared = summary(EH_AQ_model)$r.squared,
             row.names = NULL)
}))

 
#binding them for the table!
table <- merge(EH_AQ, Outlier, by = "Data_Type", all.x = TRUE)
table <- table %>% mutate(across(where(is.numeric), ~ round(., 3)))
table <- table[c("Data_Type","r_squared", "Slope", "Intercept","RMSE", "percent", "complete")]
table$complete[is.na(table$complete)] <- "100.000"

#this removes windspeed/ direction
table <- table [-c(7, 8),]

#making a table!
table1 <- table |>
  gt(
    rowname_col = "Data_Type")|>
  cols_width(everything() ~ px(105)) |>
  tab_header(
    title = ("AQMesh"),
    subtitle = ("Sensor vs. Reference Correlations"))|>
  cols_label(
    r_squared = ("R\u00b2"),
    Slope = ("Slope"),
    Intercept = ("Y-Intercept"),
    percent= ("Outlier Percentage"),
    complete= ("Data Completeness"))|>
cols_align(
  align = ("center"),
  columns = everything())|>
sub_missing(
  missing_text = "0.000")

#gtsave(table1, "table1.png")

```
# Results Summary
```{r,fig.align = 'left', results='asis', echo = FALSE}
knitr::include_graphics("table1.png")
```

<i> \*Outliers were defined from the AQMesh dataset using the IQR Method (all data points more than 1.5 below the the lower bound quartile or above the upper bound quartile). </i>
